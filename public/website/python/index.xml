<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Python on DSF</title>
    <link>/website/python/</link>
    <description>Recent content in Python on DSF</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Sat, 12 Mar 2022 18:10:08 +0800</lastBuildDate><atom:link href="/website/python/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>request HTML</title>
      <link>/website/python/3.26how-to-request-html/</link>
      <pubDate>Sat, 12 Mar 2022 18:10:08 +0800</pubDate>
      <guid>/website/python/3.26how-to-request-html/</guid>
      <description>深度优先搜索策略 HTML中获取URL，得到新的HTML文件，再从新的HTML文件中获取新的URL进行搜索。
宽度优先搜索策略 搜索完一个HTML页面，再去继续搜索下一层。
HTTP和HTTPS HTTP超文本传输协议是Server和Client请求和应答的标准（TCP）
URL统一资源定位符号
HTTPS：设计SSL安全socket层协议对HTTP协议传输的数据进行加密，从而诞生了HTTPS
SSL中使用了对称/非对称加密和HASH算法，实现网站的握手过程，保证隐私数据可以加密传输。
握手过程的简单描述：
B发送加密规则给S； S把证书（自己的身份信息/加密公钥）发给B； 证书受到用户的信任后，B生成公钥加密（非对称加密算法）的随机数密码发给S； S使用约定好的HASH计算握手消息，使用生成的随机数对消息进行加密（对称加密算法），并将所有网站信息发送给B；
请求头 描述客户端到服务器发送请求使用的协议类型：规定了浏览器可以接受的文件类型、可以接受的编码类型、浏览器可以接受的语言；请求的主机地址和端口，请求来自的页面，浏览器信息，请求时间。
Cookies 网站为了辨别身份，进行Session跟踪而存在用户本地终端上的数据。
Ajax 使用java向服务器提出请求处理响应，核心对象是XMLHTTPRequest； 在B和S中使用异步数据传输，爬虫中需要判断数据加载方式，如果没有刷新，数据就自动生成，说明数据的加载是通过ajax渲染到网页上的。
Fiddler抓包 HTTP抓包工具原理是在电脑中开启一个HTTP代理服务器，转发所有的请求和响应，爬虫需要知道每个请求的类型，状态码，请求方式，请求头，请求参数和响应内容。
Urllib python自带的标准库，可以接受Request对象来设置URL。
GET 用于从指定资源请求数据。
/test/demo_form.php?name1=value1&amp;amp;name2=value2
 GET 请求可被缓存 GET 请求保留在浏览器历史记录中 GET 请求可被收藏为书签 GET 请求不应在处理敏感数据时使用 GET 请求有长度限制 GET 请求只应当用于取回数据（不修改）  POST 用于将数据发送到服务器来创建/更新资源。
通过 POST 发送到服务器的数据存储在 HTTP 请求的请求主体中：最常见的HTTP方法。
POST /test/demo_form.php HTTP/1.1 Host: w3school.com.cn name1=value1&amp;amp;name2=value2 PUT 方法
PUT 用于将数据发送到服务器来创建/更新资源。
POST 和 PUT之间的区别在于 PUT 请求是幂等的（idempotent）。也就是说，多次调用相同的 PUT 请求将始终产生相同的结果。相反，重复调用POST请求具有多次创建相同资源的副作用。
一个发送请求的例子：
from urllib.request import Request, urlopen headers={&amp;#39;User-Agent&amp;#39;:&amp;#39;Mozilla/5.</description>
    </item>
    <item>
      <title>SCRAPY</title>
      <link>/website/python/scrapy/</link>
      <pubDate>Sat, 12 Mar 2022 18:10:08 +0800</pubDate>
      <guid>/website/python/scrapy/</guid>
      <description>定义存储字段和管道类 items.py 主要用于存储对象
Item对象  pipeline.py 用于实现对象存储（歌曲入库）和对象操作（歌曲下载）
触发对Item对象的操作，实现类初始化和数据库连接。  Spider开发之Get请求和Post请求 Post是传递参数（需要搜索的参数）到服务器，而Get请求是指明url。
Selector选择器会用XPATH和CSS表达式选择HTML中的部分数据。
然后用可以重用的Item pipelines进行文件下载和保存。
SCRAPY爬虫的运行方式  调度器中取出URL封装成Request请求给下载器 资源下载后封装成Response 解析出实体Item给pipeline处理 解析出URL则给调度器等待抓取  </description>
    </item>
  </channel>
</rss>